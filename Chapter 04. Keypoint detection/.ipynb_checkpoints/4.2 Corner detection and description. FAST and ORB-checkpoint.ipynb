{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Back to the 21st century! Using FAST and ORB\n",
    "\n",
    "The Harris corner detector has been employed in a vast amount of works since its proposal back in 1988 and it's still being used in many approaches because of its simplicity and performance. However, the computer vision community has obviously moved on in recent years and nowadays is being focused in using faster methods to detect corners. One of the most successful and popular methods for detecting corners is called **FAST** (**F**eatures from **A**ccelerated **S**egment **T**est), which, has its name suggest is clearly faster than most of the methods developed so far. [Published in 2006](https://link.springer.com/chapter/10.1007/11744023_34), the work by Rosten and Drummond claims to operate around 20x faster than the Harris method and finds a considerably large amount of keypoints (sometimes too much!).\n",
    "\n",
    "In a nutshell, in its original form, it operates by comparing the grey level of a certain pixel in the image with a surrounding circle of 16 pixels. If at least 12 consecutive pixels in that circle are brighter (or darker) than the candidate, then it is a considered as a corner. Being based just in pixel comparisons, you can imagine its speed!\n",
    "\n",
    "<img src=\"./images/fast.png\" width=\"400\">\n",
    "\n",
    "In fact, by wisely selecting the first 4 pixels to compare, fast rejection of possible candidates can be easily applied. Some variations of the original proposal have been developed later, turning the FAST-based approaches a prominent method for detecting corners nowadays.\n",
    "\n",
    "However, this method **does not provide a descriptor** for the detected corners, so, as we learnt before, they must be augmented with a descriptor in order to be matched! We could use again NCC and a patch, but in this case we are going to explore the ORB method, which is [a detection and description method](https://ieeexplore.ieee.org/abstract/document/6126544) developed in 2011 by Rublee *et.al*.\n",
    "\n",
    "ORB stands for **O**riented FAST and **R**otated **B**RIEF and combines the FAST detector with a modified version of the [BRIEF descriptor](https://link.springer.com/chapter/10.1007/978-3-642-15561-1_56). In short, ORB operates as follows:\n",
    "\n",
    "1. It detects FAST corners and computes its main orientation. \n",
    "- It rotates the sourrounding patch of the keypoint according to the main orientation.\n",
    "- It computes the BRIEF descriptor by comparing the grey level in a set of wisely selected pairs of pixels within the (rotated) patch, yielding a **binary** sequence that corresponds to the descriptor. \n",
    "\n",
    "Since the resulting descriptors are binary (i.e. sequences of bits), they can be easily compared by using the so-called [Hamming distance](https://en.wikipedia.org/wiki/Hamming_distance), which, essentially, computes the number of different bits in the two descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (20.0, 20.0)\n",
    "images_path = './images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 1: Using ORB</i></b></span>**\n",
    "\n",
    "Now let's try a simple example of using ORB. Write a script that:\n",
    "1. Loads the images 'park_l.jpeg' and 'park_r.jpeg' in grayscale.\n",
    "- Detect ORB keypoints.\n",
    "- Compute their ORB descriptor.\n",
    "- Use a Brute-Force matcher to find correspondences between both sets of keypoints. A Brute-Force matcher simply compares a certain descriptor in a list with all the rest of descriptors in an exhaustive search.\n",
    "- Order the matches according to their distance (have a look to [`sorted()`](https://wiki.python.org/moin/HowTo/Sorting) and use as key the lambda function `x:x.distance`). Set the `crossCheck` argument to `True` in order to get more robust matches.\n",
    "- Once all matches are defined, call `cv2.drawMatches` and display the resulting image with the 30 best matches. Try `cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS` as flag in this function call.\n",
    "\n",
    "*Tip: Search for some documentation regarding ORB detection/description and brute-force matching in OpenCV.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 1\n",
    "# Detect and describe keypoints using ORB in two images ('park_l.jpeg' and 'park_r.jpeg'),\n",
    "# then match them using a brute-force matcher.\n",
    "# Write your code here\n",
    "\n",
    "# Load the two previous images and convert to grayscale\n",
    "im1 = cv2.imread(images_path + 'park_l.jpeg')\n",
    "assert im1 is not None, \"Image not found!\"\n",
    "\n",
    "im2 = cv2.imread(images_path + 'park_r.jpeg')\n",
    "assert im2 is not None, \"Image not found!\"\n",
    "\n",
    "im1_gray = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "im2_gray = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect the ORB keypoints using the OpenCV method\n",
    "# -- create the ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "\n",
    "\n",
    "# -- detect ORB keypoints \n",
    "\n",
    "\n",
    "# -- compute the descriptors with ORB\n",
    "\n",
    "\n",
    "# Note: detection and description can be done in just one call\n",
    "\n",
    "# Match descriptors.\n",
    "\n",
    "\n",
    "# Sort them in the order of their distance.\n",
    "\n",
    "       \n",
    "# Display both images side-by-side along with the matches\n",
    "\n",
    "\n",
    "# And finally show them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it</i></b></font>\n",
    "\n",
    "Now you can compare this output with the one produced by Harris + NCC...\n",
    "- **What could you conclude?**\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This was a short but intense notebook covering state-of-the-art keypoint detection and description techniques such as FAST and ORB. It is exciting to stay informed of modern techniques!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
