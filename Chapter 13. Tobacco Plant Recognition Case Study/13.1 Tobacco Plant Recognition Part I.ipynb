{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b14bb52",
   "metadata": {},
   "source": [
    "# Case Study: Tobacco Plant Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a557794",
   "metadata": {},
   "source": [
    "Please read the following research paper for the problem description and objectives:\n",
    "\n",
    "**Real-Time Machine-Learning Based Crop/Weed Detection and Classification for Variable-Rate Spraying in Precision Agriculture**  \n",
    "[https://www.researchgate.net/publication/341719983_Real-Time_Machine-Learning_Based_CropWeed_Detection_and_Classification_for_Variable-Rate_Spraying_in_Precision_Agriculture](https://www.researchgate.net/publication/341719983_Real-Time_Machine-Learning_Based_CropWeed_Detection_and_Classification_for_Variable-Rate_Spraying_in_Precision_Agriculture)\n",
    "\n",
    "**Author:** Dr. Muhammad Tufail  \n",
    "**Institution:** Red Deer Polytechnic  \n",
    "**Course:** Computer Vision — Fall 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4207060c",
   "metadata": {},
   "source": [
    "# Tobacco vs. Non-Tobacco Image Classification  \n",
    "### Using Hand-Crafted Features and Random Forest\n",
    "\n",
    "This notebook demonstrates a **classical machine learning pipeline** for plant-image classification in precision agriculture.  \n",
    "It focuses on distinguishing **tobacco leaves** from **non-tobacco vegetation** such as *grass, mint, sunflower,* and *weeds* using traditional computer-vision features and a Random Forest classifier.\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "### 1️⃣ Data Preparation and Augmentation\n",
    "- Loads images from `./dataset/train/`.\n",
    "- Resizes all images to **640×480** for consistency.\n",
    "- Applies multiple augmentations to increase dataset diversity:\n",
    "  - Horizontal / vertical flips  \n",
    "  - Random rotations (±15°)  \n",
    "  - Brightness and contrast variations  \n",
    "  - Gaussian blur and Gaussian noise\n",
    "- Saves augmented images in corresponding folders (e.g., `./dataset/train/grass_aug/`).\n",
    "\n",
    "---\n",
    "\n",
    "### 2️⃣ Feature Extraction\n",
    "Each image is represented by a **global feature vector** composed of:\n",
    "- **Color Histogram (HSV):** captures dominant hues.  \n",
    "- **Haralick Texture:** quantifies spatial gray-level patterns.  \n",
    "- **Hu Moments:** invariant shape descriptors.  \n",
    "- **EOG Histogram:** gray-level intensity distribution.  \n",
    "- *(Optional)* **Edge Density:** separates thin grass blades from broad tobacco leaves.\n",
    "\n",
    "All extracted features and labels are stored in:\n",
    "\n",
    "`./output/data_tobacco_binary.h5`\n",
    "\n",
    "\n",
    "### 3️⃣ Model Training\n",
    "- Splits the dataset into **training (80%)** and **validation (20%)** using `train_test_split`.\n",
    "- Trains a **RandomForestClassifier** with:\n",
    "  - `n_estimators = 150`  \n",
    "  - `class_weight = 'balanced'`\n",
    "- Evaluates performance using accuracy, precision, recall, and F1-score.\n",
    "- Saves the trained model as:\n",
    "\n",
    "`output/tobacco_rf_model.pkl`\n",
    "\n",
    "\n",
    "### 4️⃣ Evaluation on Unseen Data\n",
    "The trained model is evaluated on a **diverse test set** located in:\n",
    "\n",
    "dataset/test/\n",
    "├── tobacco/\n",
    "├── grass/\n",
    "├── mint/\n",
    "├── sunflower/\n",
    "└── weeds/\n",
    "\n",
    "\n",
    "The notebook:\n",
    "- Loads the saved Random Forest model.  \n",
    "- Predicts each image’s class and computes:\n",
    "  - Folder-wise accuracy  \n",
    "  - Global confusion matrix and classification report  \n",
    "- Optionally saves **misclassified samples** with predicted and true labels for inspection.\n",
    "\n",
    "---\n",
    "\n",
    "### 5️⃣ Key Findings\n",
    "- Achieved **~97% overall accuracy** on the test set.  \n",
    "- Perfect classification for *mint, sunflower,* and *weeds.*  \n",
    "- Some **false positives on grass**, due to color-texture similarity with tobacco leaves.  \n",
    "- Demonstrates strengths and limits of feature-based models in real agricultural imagery.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "- Practice classical (non-deep-learning) image feature extraction.  \n",
    "- Train and evaluate a supervised model (Random Forest) for image recognition.  \n",
    "- Assess model generalization on unseen plant types.  \n",
    "- Explore feature refinement and threshold tuning to minimize false positives.\n",
    "\n",
    "---\n",
    "\n",
    "## Dependencies\n",
    "Make sure these packages are installed:\n",
    "\n",
    "- numpy\n",
    "- opencv-python\n",
    "- scikit-image\n",
    "- scikit-learn\n",
    "- matplotlib\n",
    "- mahotas\n",
    "- h5py\n",
    "- tqdm\n",
    "- joblib\n",
    "\n",
    "You can install them by running:\n",
    "\n",
    "`pip install -r requirements.txt`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32416bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4829d0",
   "metadata": {},
   "source": [
    "## Step 1: Data Augumentationn\n",
    "\n",
    "| Step                | Action                             | Output                |\n",
    "| ------------------- | ---------------------------------- | --------------------- |\n",
    "| Resize              | Converts all images to **640×480** | Standardized size     |\n",
    "| Flip                | Horizontal + vertical flips        | 2× more data          |\n",
    "| Rotate              | −15° and +15°                      | Slight view variation |\n",
    "| Brightness/contrast | Simulate lighting changes          | 2× more data          |\n",
    "| Gaussian blur       | Simulates motion/focus variations  | Adds realism          |\n",
    "| Gaussian noise      | Simulates camera grain             | Adds realism          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae50c3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing images from ./dataset/grass...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:17<00:00,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing complete. Saved 549 images in ./dataset/train/grass_aug\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_dir = \"./dataset/grass\"\n",
    "output_dir = \"./dataset/train/grass_aug\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# =====================================================\n",
    "# Helper functions\n",
    "# =====================================================\n",
    "\n",
    "def adjust_brightness_contrast(image, brightness=0, contrast=0):\n",
    "    beta = brightness\n",
    "    alpha = contrast / 127 + 1.0\n",
    "    return cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "\n",
    "def add_gaussian_noise(image, mean=0, var=20):\n",
    "    sigma = var ** 0.5\n",
    "    gauss = np.random.normal(mean, sigma, image.shape).astype('float32')\n",
    "    noisy = np.clip(image.astype('float32') + gauss, 0, 255).astype('uint8')\n",
    "    return noisy\n",
    "\n",
    "def augment_image(image):\n",
    "    \"\"\"Apply multiple random augmentations and return a list of variants\"\"\"\n",
    "    augmented = []\n",
    "\n",
    "    # Horizontal flip\n",
    "    augmented.append(cv2.flip(image, 1))\n",
    "\n",
    "    # Vertical flip\n",
    "    augmented.append(cv2.flip(image, 0))\n",
    "\n",
    "    # Rotate small angles\n",
    "    for angle in [-15, 15]:\n",
    "        (h, w) = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        rotated = cv2.warpAffine(image, M, (w, h))\n",
    "        augmented.append(rotated)\n",
    "\n",
    "    # Brightness and contrast changes\n",
    "    augmented.append(adjust_brightness_contrast(image, brightness=30, contrast=40))\n",
    "    augmented.append(adjust_brightness_contrast(image, brightness=-30, contrast=-40))\n",
    "\n",
    "    # Blur and noise\n",
    "    augmented.append(cv2.GaussianBlur(image, (5, 5), 0))\n",
    "    augmented.append(add_gaussian_noise(image))\n",
    "\n",
    "    return augmented\n",
    "\n",
    "# =====================================================\n",
    "# Process images\n",
    "# =====================================================\n",
    "\n",
    "print(f\"[INFO] Processing images from {input_dir}...\")\n",
    "counter = 0\n",
    "\n",
    "for file in tqdm(os.listdir(input_dir)):\n",
    "    if not file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        continue\n",
    "\n",
    "    img_path = os.path.join(input_dir, file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    # Resize to 640x480 (width x height)\n",
    "    resized = cv2.resize(img, (640, 480))\n",
    "\n",
    "    # Save base resized image\n",
    "    base_name = os.path.splitext(file)[0]\n",
    "    cv2.imwrite(os.path.join(output_dir, f\"{base_name}_resized.jpg\"), resized)\n",
    "    counter += 1\n",
    "\n",
    "    # Apply augmentations\n",
    "    for i, aug_img in enumerate(augment_image(resized)):\n",
    "        out_name = os.path.join(output_dir, f\"{base_name}_aug{i+1}.jpg\")\n",
    "        cv2.imwrite(out_name, aug_img)\n",
    "        counter += 1\n",
    "\n",
    "print(f\"[INFO] Preprocessing complete. Saved {counter} images in {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a1452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in e:\\anaconda3\\envs\\aida2154_python_env\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8bb61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting h5py\n",
      "  Using cached h5py-3.14.0-cp313-cp313-win_amd64.whl.metadata (2.7 kB)\n",
      "Collecting numpy>=1.19.3 (from h5py)\n",
      "  Using cached numpy-2.3.3-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Using cached h5py-3.14.0-cp313-cp313-win_amd64.whl (2.9 MB)\n",
      "Using cached numpy-2.3.3-cp313-cp313-win_amd64.whl (12.8 MB)\n",
      "Installing collected packages: numpy, h5py\n",
      "\n",
      "  Attempting uninstall: numpy\n",
      "\n",
      "    Found existing installation: numpy 2.3.1\n",
      "\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "    Uninstalling numpy-2.3.1:\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "      Successfully uninstalled numpy-2.3.1\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "  Attempting uninstall: h5py\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "    Found existing installation: h5py 3.14.0\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "    Uninstalling h5py-3.14.0:\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "      Successfully uninstalled h5py-3.14.0\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   -------------------- ------------------- 1/2 [h5py]\n",
      "   ---------------------------------------- 2/2 [h5py]\n",
      "\n",
      "Successfully installed h5py-3.14.0 numpy-2.3.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'E:\\anaconda3\\envs\\aida2154_python_env\\Lib\\site-packages\\~5py'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyfeats 1.0.1 requires mahotas, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade --force-reinstall h5py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857e8158",
   "metadata": {},
   "source": [
    "# Step 2: Train a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1a21188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting feature extraction...\n",
      "[INFO] Processing 'grass_aug' → Label: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [00:23<00:00, 23.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing 'tobacco' → Label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:11<00:00, 20.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Feature extraction complete: 799 samples\n",
      "[INFO] Saved: output/data_tobacco_binary.h5\n",
      "[INFO] Validation accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Tobacco       1.00      1.00      1.00       110\n",
      "     Tobacco       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           1.00       160\n",
      "   macro avg       1.00      1.00      1.00       160\n",
      "weighted avg       1.00      1.00      1.00       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "# =====================================================\n",
    "# Feature extraction functions\n",
    "# =====================================================\n",
    "\n",
    "def fd_histogram(image, bins=(8, 8, 8)):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "                        [0, 180, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    return hist.flatten()\n",
    "\n",
    "def fd_haralick(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    glcm = graycomatrix(gray,\n",
    "                        distances=[1],\n",
    "                        angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "                        symmetric=True,\n",
    "                        normed=True)\n",
    "    features = [\n",
    "        graycoprops(glcm, 'contrast').mean(),\n",
    "        graycoprops(glcm, 'dissimilarity').mean(),\n",
    "        graycoprops(glcm, 'homogeneity').mean(),\n",
    "        graycoprops(glcm, 'ASM').mean(),\n",
    "        graycoprops(glcm, 'energy').mean(),\n",
    "        graycoprops(glcm, 'correlation').mean()\n",
    "    ]\n",
    "    return np.array(features)\n",
    "\n",
    "def fd_hu_moments(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    moments = cv2.moments(gray)\n",
    "    hu = cv2.HuMoments(moments)\n",
    "    return hu.flatten()\n",
    "\n",
    "def fd_eoghistogram(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    return hist.flatten()\n",
    "\n",
    "# =====================================================\n",
    "# Paths and Parameters\n",
    "# =====================================================\n",
    "\n",
    "train_path = \"dataset/train\"\n",
    "h5_data = \"output/data_tobacco_binary.h5\"\n",
    "test_size = 0.2\n",
    "seed = 42\n",
    "\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# =====================================================\n",
    "# Feature extraction\n",
    "# =====================================================\n",
    "\n",
    "global_features = []\n",
    "labels = []\n",
    "\n",
    "print(\"[INFO] Starting feature extraction...\")\n",
    "\n",
    "for label_name in os.listdir(train_path):\n",
    "    dir_path = os.path.join(train_path, label_name)\n",
    "    if not os.path.isdir(dir_path):\n",
    "        continue\n",
    "\n",
    "    # Assign binary label: 1 for tobacco, 0 for everything else\n",
    "    label = 1 if label_name.lower() == \"tobacco\" else 0\n",
    "    print(f\"[INFO] Processing '{label_name}' → Label: {label}\")\n",
    "\n",
    "    for file in tqdm(os.listdir(dir_path)):\n",
    "        file_path = os.path.join(dir_path, file)\n",
    "        image = cv2.imread(file_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "\n",
    "        # Extract features\n",
    "        fv_histogram = fd_histogram(image)\n",
    "        fv_haralick = fd_haralick(image)\n",
    "        fv_hu_moments = fd_hu_moments(image)\n",
    "        fv_eoghistogram = fd_eoghistogram(image)\n",
    "\n",
    "        global_feature = np.hstack([\n",
    "            fv_histogram,\n",
    "            fv_haralick,\n",
    "            fv_hu_moments,\n",
    "            fv_eoghistogram\n",
    "        ])\n",
    "\n",
    "        global_features.append(global_feature)\n",
    "        labels.append(label)\n",
    "\n",
    "print(f\"[INFO] Feature extraction complete: {len(global_features)} samples\")\n",
    "\n",
    "# Save features\n",
    "with h5py.File(h5_data, 'w') as f:\n",
    "    f.create_dataset('features', data=np.array(global_features))\n",
    "    f.create_dataset('labels', data=np.array(labels))\n",
    "print(f\"[INFO] Saved: {h5_data}\")\n",
    "\n",
    "# =====================================================\n",
    "# Train binary classifier\n",
    "# =====================================================\n",
    "\n",
    "X = np.array(global_features)\n",
    "y = np.array(labels)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=seed, stratify=y\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=150, class_weight='balanced', random_state=seed)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_val)\n",
    "print(\"[INFO] Validation accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred, target_names=[\"Non-Tobacco\", \"Tobacco\"]))\n",
    "\n",
    "# =====================================================\n",
    "# Inference\n",
    "# =====================================================\n",
    "\n",
    "def predict_image(img_path, threshold=0.6):\n",
    "    image = cv2.imread(img_path)\n",
    "    if image is None:\n",
    "        return \"Invalid image\"\n",
    "\n",
    "    fv_histogram = fd_histogram(image)\n",
    "    fv_haralick = fd_haralick(image)\n",
    "    fv_hu_moments = fd_hu_moments(image)\n",
    "    fv_eoghistogram = fd_eoghistogram(image)\n",
    "\n",
    "    feature = np.hstack([fv_histogram, fv_haralick, fv_hu_moments, fv_eoghistogram]).reshape(1, -1)\n",
    "    prob = clf.predict_proba(feature)[0][1]  # probability of being 'Tobacco'\n",
    "    print(\"Tobacco probability:\", prob)\n",
    "\n",
    "\n",
    "    return \"Tobacco\" if prob > threshold else \"Non-Tobacco\"\n",
    "\n",
    "# Example\n",
    "# print(\"[TEST] \", predict_image(\"dataset/test/sample.jpg\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc9ce26",
   "metadata": {},
   "source": [
    "### Analyzing the output:\n",
    "\n",
    "| Class       | Samples | Notes                                      |\n",
    "| ----------- | ------- | ------------------------------------------ |\n",
    "| `grass_aug` | 549     | non-tobacco negatives (augmented, diverse) |\n",
    "| `tobacco`   | 250     | positive images                            |\n",
    "| **Total**   | **799** | balanced, healthy dataset size             |\n",
    "\n",
    "The Random Forest classifier has achieved:\n",
    "\n",
    "Validation accuracy: 1.0\n",
    "\n",
    "Precision/Recall/F1 for both classes: 1.0\n",
    "\n",
    "That’s ideal on internal validation, meaning:\n",
    "\n",
    "- The augmented negatives are sufficiently distinct from tobacco,\n",
    "- The feature descriptors (color histogram + Haralick + Hu + EOG) are highly discriminative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c227d32c",
   "metadata": {},
   "source": [
    "### 2.1. Save your trained RF model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa2a6ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./output/tobacco_rf_model.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, \"./output/tobacco_rf_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7e5489",
   "metadata": {},
   "source": [
    "### 2.2. Relad the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2925d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load(\"output/tobacco_rf_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7f4efa",
   "metadata": {},
   "source": [
    "# Step 3: Model Evaluation\n",
    "\n",
    "The following cell does:\n",
    "\n",
    "- It automatically detects all subfolders under dataset/test/.\n",
    "- Treats anything not named “tobacco” as non-tobacco (label = 0).\n",
    "- Evaluates and reports results per subfolder so you can see how your classifier behaves for each category (grass vs mint vs sunflower vs weeds).\n",
    "\n",
    "How it works:\n",
    "\n",
    "| Step | Action                                                             |\n",
    "| ---- | ------------------------------------------------------------------ |\n",
    "| 1️⃣  | Loads your trained `tobacco_rf_model.pkl`                          |\n",
    "| 2️⃣  | Iterates through *every folder* in `dataset/test/`                 |\n",
    "| 3️⃣  | Assigns label = 1 for `\"tobacco\"`; label = 0 for all other folders |\n",
    "| 4️⃣  | Extracts same feature vectors (color histogram, Haralick, Hu, EOG) |\n",
    "| 5️⃣  | Predicts and computes per-folder and global accuracy               |\n",
    "| 6️⃣  | Prints a confusion matrix and classification report                |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1991db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded model from ./output/tobacco_rf_model.pkl\n",
      "[INFO] Scanning subfolders in ./dataset/test...\n",
      "\n",
      "[INFO] Processing folder: grass (Label=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Accuracy for 'grass': 0.43\n",
      "[INFO] Processing folder: mint (Label=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Accuracy for 'mint': 1.00\n",
      "[INFO] Processing folder: sunflower (Label=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Accuracy for 'sunflower': 1.00\n",
      "[INFO] Processing folder: tobacco (Label=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:14<00:00, 17.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Accuracy for 'tobacco': 0.98\n",
      "[INFO] Processing folder: weeds (Label=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    → Accuracy for 'weeds': 1.00\n",
      "\n",
      "=================== GLOBAL REPORT ===================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Tobacco       0.76      0.76      0.76        17\n",
      "     Tobacco       0.98      0.98      0.98       250\n",
      "\n",
      "    accuracy                           0.97       267\n",
      "   macro avg       0.87      0.87      0.87       267\n",
      "weighted avg       0.97      0.97      0.97       267\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 13   4]\n",
      " [  4 246]]\n",
      "\n",
      "Per-Class Accuracy:\n",
      "  grass      : 0.43\n",
      "  mint       : 1.00\n",
      "  sunflower  : 1.00\n",
      "  tobacco    : 0.98\n",
      "  weeds      : 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import joblib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "# =====================================================\n",
    "# Feature extraction functions (same as training)\n",
    "# =====================================================\n",
    "def fd_histogram(image, bins=(8, 8, 8)):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "                        [0, 180, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    return hist.flatten()\n",
    "\n",
    "def fd_haralick(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    glcm = graycomatrix(gray,\n",
    "                        distances=[1],\n",
    "                        angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "                        symmetric=True,\n",
    "                        normed=True)\n",
    "    features = [\n",
    "        graycoprops(glcm, 'contrast').mean(),\n",
    "        graycoprops(glcm, 'dissimilarity').mean(),\n",
    "        graycoprops(glcm, 'homogeneity').mean(),\n",
    "        graycoprops(glcm, 'ASM').mean(),\n",
    "        graycoprops(glcm, 'energy').mean(),\n",
    "        graycoprops(glcm, 'correlation').mean()\n",
    "    ]\n",
    "    return np.array(features)\n",
    "\n",
    "def fd_hu_moments(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    moments = cv2.moments(gray)\n",
    "    hu = cv2.HuMoments(moments)\n",
    "    return hu.flatten()\n",
    "\n",
    "def fd_eoghistogram(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    return hist.flatten()\n",
    "\n",
    "# =====================================================\n",
    "# Paths\n",
    "# =====================================================\n",
    "model_path = \"./output/tobacco_rf_model.pkl\"\n",
    "test_path = \"./dataset/test\"\n",
    "\n",
    "clf = joblib.load(model_path)\n",
    "print(f\"[INFO] Loaded model from {model_path}\")\n",
    "\n",
    "# =====================================================\n",
    "# Evaluate all subfolders\n",
    "# =====================================================\n",
    "true_labels, pred_labels = [], []\n",
    "folder_results = {}\n",
    "\n",
    "print(f\"[INFO] Scanning subfolders in {test_path}...\\n\")\n",
    "\n",
    "for folder_name in sorted(os.listdir(test_path)):\n",
    "    folder_path = os.path.join(test_path, folder_name)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    label = 1 if folder_name.lower() == \"tobacco\" else 0\n",
    "    folder_true, folder_pred = [], []\n",
    "\n",
    "    print(f\"[INFO] Processing folder: {folder_name} (Label={label})\")\n",
    "\n",
    "    for file in tqdm(os.listdir(folder_path)):\n",
    "        if not file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(folder_path, file)\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "\n",
    "        # Extract same features as in training\n",
    "        fv_histogram = fd_histogram(image)\n",
    "        fv_haralick = fd_haralick(image)\n",
    "        fv_hu_moments = fd_hu_moments(image)\n",
    "        fv_eoghistogram = fd_eoghistogram(image)\n",
    "        feature = np.hstack([fv_histogram, fv_haralick, fv_hu_moments, fv_eoghistogram]).reshape(1, -1)\n",
    "\n",
    "        pred = clf.predict(feature)[0]\n",
    "        folder_true.append(label)\n",
    "        folder_pred.append(pred)\n",
    "\n",
    "    # Record per-folder results\n",
    "    if len(folder_true) > 0:\n",
    "        cm = confusion_matrix(folder_true, folder_pred, labels=[0, 1])\n",
    "        acc = np.trace(cm) / np.sum(cm)\n",
    "        folder_results[folder_name] = acc\n",
    "        print(f\"    → Accuracy for '{folder_name}': {acc:.2f}\")\n",
    "\n",
    "    true_labels.extend(folder_true)\n",
    "    pred_labels.extend(folder_pred)\n",
    "\n",
    "# =====================================================\n",
    "# Global report\n",
    "# =====================================================\n",
    "print(\"\\n=================== GLOBAL REPORT ===================\")\n",
    "print(classification_report(true_labels, pred_labels, target_names=[\"Non-Tobacco\", \"Tobacco\"]))\n",
    "\n",
    "cm_global = confusion_matrix(true_labels, pred_labels, labels=[0, 1])\n",
    "print(\"Confusion Matrix:\\n\", cm_global)\n",
    "\n",
    "print(\"\\nPer-Class Accuracy:\")\n",
    "for name, acc in folder_results.items():\n",
    "    print(f\"  {name:10s} : {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c262b84",
   "metadata": {},
   "source": [
    "### 3.1. Let's analyze the evaluation results\n",
    "\n",
    "| Folder        | Label       | Accuracy | Notes                                    |\n",
    "| ------------- | ----------- | -------- | ---------------------------------------- |\n",
    "| **grass**     | Non-tobacco | ⚠️ 0.43  | The only class still confusing the model |\n",
    "| **mint**      | Non-tobacco | ✅ 1.00   | Perfect — looks structurally different   |\n",
    "| **sunflower** | Non-tobacco | ✅ 1.00   | Distinct color and shape                 |\n",
    "| **weeds**     | Non-tobacco | ✅ 1.00   | Well separated                           |\n",
    "| **tobacco**   | Tobacco     | ✅ 0.98   | Excellent internal consistency           |\n",
    "\n",
    "\n",
    "Overall accuracy: 0.97\n",
    "\n",
    "F1-score (macro): 0.87\n",
    "\n",
    "So, your RandomForest correctly identifies most tobacco and non-tobacco classes but still mistakes 4 grass images as tobacco."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfc8036",
   "metadata": {},
   "source": [
    "🔍 Why “grass” is the hardest\n",
    "\n",
    "Grass and young tobacco plants share:\n",
    "\n",
    "- Similar green color histograms in HSV space,\n",
    "\n",
    "- Comparable leaf textures under similar lighting,\n",
    "\n",
    "- Overlapping Haralick and EOG features (since both have high local contrast and repetitive textures).\n",
    "\n",
    "Your current model is feature-driven (hand-crafted color and texture descriptors), so when the background or lighting matches, it leans toward the dominant class (tobacco)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766bfdc2",
   "metadata": {},
   "source": [
    "# Step 4 (OPTIONAL): Suggested Extensions\n",
    "- Collect additional grass images under varied lighting and angles.  \n",
    "- Tune the prediction threshold (`prob > 0.7`) to reduce false positives.  \n",
    "- Add shape-based descriptors (e.g., edge density).  \n",
    "- Compare Random Forest performance with a lightweight CNN (MobileNetV2 or EfficientNet-B0).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aida2154_python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
